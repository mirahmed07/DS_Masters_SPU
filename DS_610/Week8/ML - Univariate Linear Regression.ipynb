{"cells":[{"cell_type":"markdown","source":["# Machine Learning with Spark\n\nMachine learning is a process for extracting patterns from your data, using statistics, linear algebra, and numerical optimization. This notebook focuses on supervised learning, with linear regression. Specifically, focuses on univariate linear regression. Univariate linear regression focuses on determining relationship between one independent (explanatory variable) variable and one dependent variable."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9b184fa-01de-4f40-a9f9-2257daceea59"}}},{"cell_type":"markdown","source":["### Dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a52635d2-7daf-406e-9a59-a5a0a0fa4f2b"}}},{"cell_type":"code","source":["# the directory of the dataset, the files, etc.\ndisplay(dbutils.fs.ls('/databricks-datasets/learning-spark-v2/sf-airbnb/'))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f97e7396-68f7-4414-8888-e3ae802a225a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/README-sf-airbnb.md","README-sf-airbnb.md",1064,1575931327000],["dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/lr-pipeline-model/","lr-pipeline-model/",0,1665977670565],["dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean-100p.parquet/","sf-airbnb-clean-100p.parquet/",0,1665977670565],["dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean.parquet/","sf-airbnb-clean.parquet/",0,1665977670565],["dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-numeric.csv","sf-airbnb-numeric.csv",554979,1588481870000],["dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb.csv","sf-airbnb.csv",34234636,1575931330000]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"},{"name":"modificationTime","type":"\"long\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/README-sf-airbnb.md</td><td>README-sf-airbnb.md</td><td>1064</td><td>1575931327000</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/lr-pipeline-model/</td><td>lr-pipeline-model/</td><td>0</td><td>1665977670565</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean-100p.parquet/</td><td>sf-airbnb-clean-100p.parquet/</td><td>0</td><td>1665977670565</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean.parquet/</td><td>sf-airbnb-clean.parquet/</td><td>0</td><td>1665977670565</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-numeric.csv</td><td>sf-airbnb-numeric.csv</td><td>554979</td><td>1588481870000</td></tr><tr><td>dbfs:/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb.csv</td><td>sf-airbnb.csv</td><td>34234636</td><td>1575931330000</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["filePath = \"\"\"/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean.parquet/\"\"\"\nairbnbDF = spark.read.parquet(filePath)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"102727b7-6b85-45f7-88f0-af028cc06a9c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["airbnbDF.columns\nairbnbDF.select(\"neighbourhood_cleansed\", \"room_type\", \"bedrooms\", \"bathrooms\",\n                \"number_of_reviews\", \"price\").show(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e489c65-85c9-48a1-bd0a-5f86a9f47f76"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------+---------------+--------+---------+-----------------+-----+\n|neighbourhood_cleansed|      room_type|bedrooms|bathrooms|number_of_reviews|price|\n+----------------------+---------------+--------+---------+-----------------+-----+\n|      Western Addition|Entire home/apt|     1.0|      1.0|            180.0|170.0|\n|        Bernal Heights|Entire home/apt|     2.0|      1.0|            111.0|235.0|\n|        Haight Ashbury|   Private room|     1.0|      4.0|             17.0| 65.0|\n|        Haight Ashbury|   Private room|     1.0|      4.0|              8.0| 65.0|\n|      Western Addition|Entire home/apt|     2.0|      1.5|             27.0|785.0|\n+----------------------+---------------+--------+---------+-----------------+-----+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------+---------------+--------+---------+-----------------+-----+\nneighbourhood_cleansed|      room_type|bedrooms|bathrooms|number_of_reviews|price|\n+----------------------+---------------+--------+---------+-----------------+-----+\n      Western Addition|Entire home/apt|     1.0|      1.0|            180.0|170.0|\n        Bernal Heights|Entire home/apt|     2.0|      1.0|            111.0|235.0|\n        Haight Ashbury|   Private room|     1.0|      4.0|             17.0| 65.0|\n        Haight Ashbury|   Private room|     1.0|      4.0|              8.0| 65.0|\n      Western Addition|Entire home/apt|     2.0|      1.5|             27.0|785.0|\n+----------------------+---------------+--------+---------+-----------------+-----+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Creating Training and Test Datasets\n\nBefore we begin feature engineering and modeling, we will divide our data set into two groups: train and test. Depending on the size of your data set, your train/test ratio may vary, but many data scientists use 80/20 as a standard train/test split."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efa80ccd-c94c-447b-8c27-6ab85b7181ac"}}},{"cell_type":"code","source":["trainDF, testDF = airbnbDF.randomSplit([.8, .2], seed=42)\nprint(f\"train: {trainDF.count()} - test {testDF.count()}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"71e621df-4034-4b70-8d79-8590a2d707bf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">train: 5780 - test 1366\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">train: 5780 - test 1366\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# caching the training set is helpful since the dataset will be used many times during eda, ml, etc.\ntrainDF.cache()\n# this action is necessary to eagerly trigger the caching\ntrainDF.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51e2ced7-3941-440b-a595-ac5665243aa7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[5]: 5780</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[5]: 5780</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# notice the run of this cell is less than the above, since the dataframe is cached already\ntrainDF.count()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92641f10-cb70-4e1e-9996-32379c041092"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[6]: 5780</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[6]: 5780</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Preparing Features with Transformers\n\nThis step prepares the data to build a linear regression model predicting price given the number of bedrooms. Linear regression requires that all the input features are contained within a single vector in your DataFrame. Thus, we need to transform our data.\n\n[VectorAssembler](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html#vectorassembler) takes a list of input columns and creates a new DataFrame with an additional column, which we will call features. It combines the values of those input columns into a single vector."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"44245b9c-f599-4432-a70a-25de992cf431"}}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\nvecAssember = VectorAssembler(inputCols=['bedrooms'], outputCol='features')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0de2f81-02eb-4a97-9747-d8ac6a4ff368"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["vecTrainDF = vecAssember.transform(trainDF)\nvecTrainDF.select(['bedrooms', 'features', 'price']).show(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3aad8c4e-d256-42df-9582-1786fd9cebe6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------+--------+-----+\n|bedrooms|features|price|\n+--------+--------+-----+\n|     1.0|   [1.0]|200.0|\n|     1.0|   [1.0]|130.0|\n|     1.0|   [1.0]| 95.0|\n+--------+--------+-----+\nonly showing top 3 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------+-----+\nbedrooms|features|price|\n+--------+--------+-----+\n     1.0|   [1.0]|200.0|\n     1.0|   [1.0]|130.0|\n     1.0|   [1.0]| 95.0|\n+--------+--------+-----+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["trainDF.count(), len(trainDF.columns), ' ', vecTrainDF.count(), len(vecTrainDF.columns) "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1cd10cb-3a99-4dec-abb6-240a38bc70cf"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[9]: (5780, 34, &#39; &#39;, 5780, 35)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: (5780, 34, &#39; &#39;, 5780, 35)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Using Estimator to Build the Model\n\nwith `VectorAssembler`, we have our data prepared and transformed into a format that our linear regression model expects. In Spark, [LinearRegression](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html?highlight=linearregression#linearregression) is a type of estimator — it takes in a DataFrame and returns a Model. \n\nEstimators **learn** parameters from your data, have an estimator_name.fit() method, and are eagerly evaluated (i.e., kick off Spark jobs), whereas transformers are lazily evaluated."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"edf34fdd-3a4f-45ce-9e96-189c96418bd1"}}},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\n\nlr = LinearRegression(featuresCol='features', labelCol='price')\nlrModel = lr.fit(vecTrainDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3b0ead0-6c23-49df-a805-02b85038b481"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(\"price = {m:.2f} * bedrooms + {b:.2f}\".format(\n    m=lrModel.coefficients[0], b=lrModel.intercept))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9440e098-9267-40b6-a233-4407ae077ff0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">price = 123.68 * bedrooms + 47.51\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">price = 123.68 * bedrooms + 47.51\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Creating a Pipeline\n\nIf we want to apply our model to our test set, then we need to prepare that data in the same way as the training set (i.e., pass it through the vector assembler). Oftentimes data preparation pipelines will have multiple steps, and it becomes cumbersome to remember not only which steps to apply, but also the ordering of the steps. \n\nIn Spark, Pipelines are esti‐ mators, whereas PipelineModels—fitted Pipelines—are transformers."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2daee093-5f5c-4e8a-b1e2-584afcd61b70"}}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[vecAssember, lr])\npipelineModel = pipeline.fit(trainDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2f8435fb-e35a-49fb-9a32-578c7332d691"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["predDF = pipelineModel.transform(testDF)\npredDF.select('bedrooms', 'features', 'price', 'prediction').show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4cd9a26-c722-43a8-b90b-b7cde9083d86"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------+--------+------+------------------+\n|bedrooms|features| price|        prediction|\n+--------+--------+------+------------------+\n|     1.0|   [1.0]|  85.0|171.18598011578285|\n|     1.0|   [1.0]|  45.0|171.18598011578285|\n|     1.0|   [1.0]|  70.0|171.18598011578285|\n|     1.0|   [1.0]| 128.0|171.18598011578285|\n|     1.0|   [1.0]| 159.0|171.18598011578285|\n|     2.0|   [2.0]| 250.0|294.86172649777757|\n|     1.0|   [1.0]|  99.0|171.18598011578285|\n|     1.0|   [1.0]|  95.0|171.18598011578285|\n|     1.0|   [1.0]| 100.0|171.18598011578285|\n|     1.0|   [1.0]|2010.0|171.18598011578285|\n+--------+--------+------+------------------+\nonly showing top 10 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------+------+------------------+\nbedrooms|features| price|        prediction|\n+--------+--------+------+------------------+\n     1.0|   [1.0]|  85.0|171.18598011578285|\n     1.0|   [1.0]|  45.0|171.18598011578285|\n     1.0|   [1.0]|  70.0|171.18598011578285|\n     1.0|   [1.0]| 128.0|171.18598011578285|\n     1.0|   [1.0]| 159.0|171.18598011578285|\n     2.0|   [2.0]| 250.0|294.86172649777757|\n     1.0|   [1.0]|  99.0|171.18598011578285|\n     1.0|   [1.0]|  95.0|171.18598011578285|\n     1.0|   [1.0]| 100.0|171.18598011578285|\n     1.0|   [1.0]|2010.0|171.18598011578285|\n+--------+--------+------+------------------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b3df1a3-699e-4c8a-99e1-1032f70b65c0"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ML","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1042415759750720}},"nbformat":4,"nbformat_minor":0}
