se = sqrt(p * (1-p)/n)
se
p - qnorm(.95) * se
p + qnorm(.95) * se
p
se = sqrt(p * (1-p)/n)
se
p - qnorm(.95) * se
p + qnorm(.95) * se
prop.test(x=1,n=277,p = .019, alternative = "less", conf.level = .975, correct = F)
prop.test(x=1,n=277,p = .019, alternative = "less", conf.level = .95, correct = F)
p = 1
n = 277
p0 = .019
z = (p-p0)/sqrt(p0*(1-p0)/n)
z
pnorm(z, lower.tail=FALSE)
qnorm(.98)
qnorm(.99)
qnorm(.95)
qnorm(.95, lower.tail = T)
qnorm(.95, lower.tail = F)
qnorm(.95, lower.tail = T)
qnorm(.5, lower.tail = T)
qnorm(.05, lower.tail = T)
qnorm(.05, lower.tail = F)
# 95%
qnorm(.025, lower.tail = F)
# 95% 2 tailed
qnorm(.025, lower.tail = F)
# 98% 2 tailed
qnorm(.01, lower.tail = F)
# 98% 2 tailed
qnorm(.01, lower.tail = T)
# 98% 2 tailed
qnorm(.01, lower.tail = F)
```{r}
# 95% 2 tailed
qnorm(.975, lower.tail = F)
# 95% 2 tailed
qnorm(.975, lower.tail = T)
230 + 1.96*10/sqrt(10)
230 + 1.96*10/sqrt(100)
230 - 1.96*10/sqrt(100)
View(data)
#With the given data
dat = data.frame(category = c(1,2,3,4,5), observed = c(139,102,41,78,140))
dat
summary(dat)
#With the given data
dat = data.frame(category = c(1,2,3,4,5), observed = c(139,102,41,78,140))
dat
summary(dat)
s = sd(dat$observed)
m = mean(dat$observed)
n = sum(dat[,2])
n
# For first category, the probability of less than or equal to -0.6
p1 = pnorm(-.6,lower.tail = T)
# For second category, the probability of greater than -0.6 and less than or equal to -0.1
p2 = pnorm(-.1,lower.tail = T) - pnorm(-.6,lower.tail = T)
# For third category, the probability of greater than -0.1 and less than or equal to 0.1
p3 = pnorm(.1,lower.tail = T) - pnorm(-.1,lower.tail = T)
# For fourth category, the probability of greater than 0.1 and less than or equal to 0.6
p4 = pnorm(.6,lower.tail = T) - pnorm(.1,lower.tail = T)
# For fifth category, the probability of greater than 0.6
p5 = pnorm(.6,lower.tail = F)
dat$expected = c(n*p1, n*p2, n*p3, n*p4, n*p5)
dat$"(o-E)^2" = (dat$observed-dat$expected)^2
dat$"(o-E)^2/E" = dat$`(o-E)^2`/dat$expected
dat
# Chi-square value
chisq = sum(dat$`(o-E)^2/E`)
chisq
qchisq(.05, df, lower.tail=TRUE)
qchisq(p = .05, df, lower.tail=TRUE)
qchisq(p = .05, df = d_f, lower.tail=TRUE)
# Chi-square value
chisq = sum(dat$`(o-E)^2/E`)
chisq
# Degree of freedom (n-1)
d_f = length(dat)-1
d_f
qchisq(p = .05, df = d_f, lower.tail=TRUE)
qchisq(p = .05, df = d_f, lower.tail=F)
(10-18.5)/(3/sqrt(50))
pt(-20,49)
pt(-20,49, lower.tail = F)
pt(-20,49, lower.tail = T)
library(BSDA)
tsum.test(
mean.x = 10,
s.x = 3,
n.x = 50,
mean.y = NULL,
s.y = NULL,
n.y = NULL,
alternative = "less",
mu = 14,
var.equal = FALSE,
conf.level = 0.95
)
tsum.test(
mean.x = 10,
s.x = 3,
n.x = 50,
mean.y = NULL,
s.y = NULL,
n.y = NULL,
alternative = "less",
mu = 18.5,
var.equal = FALSE,
conf.level = 0.95
)
pt(-20.03469,49, lower.tail = T)
tsum.test(
mean.x = 14.5,
s.x = 14.85,
n.x = 8,
mean.y = NULL,
s.y = NULL,
n.y = NULL,
alternative = "less",
mu = 18.5,
var.equal = FALSE,
conf.level = 0.95
)
tsum.test(
mean.x = 14.5,
s.x = 14.85,
n.x = 8,
mean.y = NULL,
s.y = NULL,
n.y = NULL,
alternative = "two.sided",
mu = 18.5,
var.equal = FALSE,
conf.level = 0.95
)
tsum.test(
mean.x = 14.5,
s.x = 14.85,
n.x = 8,
mean.y = NULL,
s.y = NULL,
n.y = NULL,
alternative = "less",
mu = 18.5,
var.equal = FALSE,
conf.level = 0.95
)
z.test(
x = 14.5,
y = NULL,
alternative = "two.sided",
mu = 18.5,
sigma.x = 14.85,
sigma.y = NULL,
conf.level = 0.95
)
z.test(
x = 14.5,
y = NULL,
alternative = "less",
mu = 18.5,
sigma.x = 14.85,
sigma.y = NULL,
conf.level = 0.95
)
z.test(
x = 14.5,
y = NULL,
alternative = "two.sided",
mu = 18.5,
sigma.x = 14.85,
sigma.y = NULL,
conf.level = 0.95
)
z.test(
x = 100,
y = NULL,
alternative = "two.sided",
mu = 18.5,
sigma.x = 14.85,
sigma.y = NULL,
conf.level = 0.95
)
z.test(
x = 1000,
y = NULL,
alternative = "two.sided",
mu = 18.5,
sigma.x = 14.85,
sigma.y = NULL,
conf.level = 0.95
)
z.test(
x = 1000,
y = N0ULL,
alternative = "two.sided",
mu = 18.5,
sigma.x = 14.85,
sigma.y = NULL,
conf.level = 0.95
)
z.test(
x = 10000,
y = NULL,
alternative = "two.sided",
mu = 18.5,
sigma.x = 14.85,
sigma.y = NULL,
conf.level = 0.95
)
z.test(
x = 10000,
y = NULL,
alternative = "two.sided",
mu = 0,
sigma.x = 14.85,
sigma.y = NULL,
conf.level = 0.95
)
z.test(
x = 10000,
y = NULL,
alternative = "two.sided",
mu = 18.5,
sigma.x = 1,
sigma.y = NULL,
conf.level = 0.95
)
x <- rnorm(12)
z.test(x,sigma.x=1)
z.test(
x = rnorm(8, mean = 14.5, sd = 14.85/sqrt(8)),
y = NULL,
alternative = "two.sided",
mu = 18.5,
sigma.x = 14.85,
sigma.y = NULL,
conf.level = 0.95
)
zsum.test(
mean.x = 14.5,
sigma.x = 14.85,
n.x = 8,
mean.y = NULL,
sigma.y = NULL,
n.y = NULL,
alternative = "two.sided",
mu = 18.5,
conf.level = 0.95
)
zsum.test(
mean.x = 14.5,
sigma.x = 14.85,
n.x = 8,
mean.y = NULL,
sigma.y = NULL,
n.y = NULL,
alternative = "less",
mu = 18.5,
conf.level = 0.95
)
x = c(3,5,6,9,4,3)
y = c(7,8,7,9,8,9)
z.test(
x = x,
y = y,
alternative = "less",
mu = 0,
sigma.x = sd(x),
sigma.y = sd(y),
conf.level = 0.95
)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = FALSE, var.equal = FALSE,
conf.level = 0.95, ...)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = FALSE, var.equal = FALSE,
conf.level = 0.95)
mean(x) - mean(y)
var.test(x,y)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = FALSE, var.equal = T,
conf.level = 0.95)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = FALSE, var.equal = FALSE,
conf.level = 0.95)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = T, var.equal = FALSE,
conf.level = 0.95)
z.test(
x = x,
y = y,
alternative = "less",
mu = 0,
sigma.x = sd(x),
sigma.y = sd(y),
conf.level = 0.95
)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = F, var.equal = FALSE,
conf.level = 0.95)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = F, var.equal = T,
conf.level = 0.95)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = F, var.equal = F,
conf.level = 0.95)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = T, var.equal = F,
conf.level = 0.95)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = F, var.equal = F,
conf.level = 0.95)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = F, var.equal = T,
conf.level = 0.95)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = T, var.equal = T,
conf.level = 0.95)
t.test(x = x, y = y,
alternative = c("less"),
mu = 0, paired = F, var.equal = T,
conf.level = 0.95)
my_data = data.frame(name = paste0(rep("mice_", 10),1:10), weight = round(rnorm(10,20,2),1))
my_data
t,test(my_data$weight, mu =25)
t.test(my_data$weight, mu =25)
set.seed(1234)
my_data = data.frame(name = paste0(rep("mice_", 10),1:10), weight = round(rnorm(10,20,2),1))
my_data
t.test(my_data$weight, mu =25)
set.seed(1234)
my_data = data.frame(name = paste0(rep("mice_", 10),1:10), weight = round(rnorm(10,20,2),1))
my_data
t.test(my_data$weight, mu =25)
# set.seed(1234)
my_data = data.frame(name = paste0(rep("mice_", 10),1:10), weight = round(rnorm(10,20,2),1))
my_data
t.test(my_data$weight, mu =25)
# set.seed(1234)
my_data = data.frame(name = paste0(rep("mice_", 10),1:10), weight = round(rnorm(10,20,2),1))
my_data
t.test(my_data$weight, mu =25)
t.test(my_data$weight, mu =25)
# set.seed(1234)
my_data = data.frame(name = paste0(rep("mice_", 10),1:10), weight = round(rnorm(10,20,2),1))
my_data
t.test(my_data$weight, mu =25)
t.test(my_data$weight, mu =25, alternative = "less")
t.test(my_data$weight, mu =25, alternative = "greater")
t.test(my_data$weight, mu =25, alternative = "two.sided")
qnorm(z)
x = 12.170789
m = 2
s = 8.276280
n = 9626
z = (x-m)/(s/sqrt(n))
qnorm(z)
x = 12.170789
m = 2
s = 8.276280
n = 9626
z = (x-m)/(s/sqrt(n))
z
z = (x-m)/(s)
x = 12.170789
m = 2
s = 8.276280
n = 9626
z = (x-m)/(s)
z
pnorm(z, mean = m, sd = s, lower.tail = F)
pnorm(z, mean = m, sd = 1, lower.tail = F)
pnorm(z, mean = 0, sd = 1, lower.tail = F)
pnorm(z, mean = m, sd = s/n, lower.tail = F)
pnorm(z, mean = m, sd = s, lower.tail = F)
x = 12.170789
m = 2
s = 8.276280
n = 9626
z = (x-m)/s
z
pnorm(z, mean = m, sd = s, lower.tail = F)
pnorm(z, lower.tail = F)
pnorm(z, mean = m, sd = s, lower.tail = F)
pnorm(x, mean = m, sd = s, lower.tail = F)
pnorm(x, mean = m, sd = s/sqrt(n), lower.tail = F)
pnorm(z, mean = m, sd = s/sqrt(n), lower.tail = F)
pnorm(x, mean = m, sd = s/sqrt(n), lower.tail = F)
pnorm(z, mean = m, sd = s/sqrt(n), lower.tail = F)
pnorm(x, mean = m, sd = s/sqrt(n), lower.tail = F)
pnorm(z, mean = m, sd = s/sqrt(n), lower.tail = F)
pnorm(x, mean = m, sd = s/sqrt(n), lower.tail = F)
x = 12.170789
m = 2
s = 8.276280
n = 9626
z = (x-m)/(s/sqrt(n))
z
pnorm(z, mean = m, sd = s/sqrt(n), lower.tail = F)
z
#load necessary libraries
library(dplyr)
library(readxl)
library(ggplot2)
library(ggpubr)
library(qqplotr)
#library(car)
library(e1071)
library(nortest)
library(BSDA)
file_name = "fidelity_mutual_funds_return_w_risk.csv"
df = read.csv(file_name)
setwd("C:/Users/mosab/DS_Masters/DS_520/final_project")
file_name = "fidelity_mutual_funds_return_w_risk.csv"
df = read.csv(file_name)
df
str(df)
summary(df)
# Removing all case with null value in any columns
df <- na.omit(df)
summary(df)
# Scatter plot of matrices
pairs.panels(df[,2:],method = "pearson",hist.col ="#00AFBB" ,density = TRUE,ellipses = TRUE)
# Scatter plot of matrices
pairs.panels(df[,2:18],method = "pearson",hist.col ="#00AFBB" ,density = TRUE,ellipses = TRUE)
#load necessary libraries
library(dplyr)
library(readxl)
library(ggplot2)
library(ggpubr)
library(qqplotr)
#library(car)
library(e1071)
library(nortest)
library(BSDA)
library(psych)
library(caret)
library(leaps)
library(gvlma)
# Scatter plot of matrices
pairs.panels(df[,2:18],method = "pearson",hist.col ="#00AFBB" ,density = TRUE,ellipses = TRUE)
# Scatter plot of matrices
pairs.panels(df[,2:18],method = "pearson",hist.col ="#00AFBB" ,density = TRUE,ellipses = TRUE)
resize.win <- function(Width=6, Height=6)
{
# works for windows
dev.off(); # dev.new(width=6, height=6)
windows(record=TRUE, width=Width, height=Height)
}
resize.win <- function(Width=6, Height=6)
{
# works for windows
dev.off(); # dev.new(width=6, height=6)
windows(record=TRUE, width=Width, height=Height)
}
resize.win(10,10)
resize.win <- function(Width=6, Height=6)
{
# works for windows
#dev.off(); # dev.new(width=6, height=6)
windows(record=TRUE, width=Width, height=Height)
}
resize.win(10,10)
# Scatter plot of matrices
pairs.panels(df[,2:18],method = "pearson",hist.col ="#00AFBB" ,density = TRUE,ellipses = TRUE)
# Scatter plot of matrices
pairs(df[,2:18],method = "pearson",hist.col ="#00AFBB" ,density = TRUE,ellipses = TRUE)
# Scatter plot of matrices
dev.new(width=10, height=4)
# Scatter plot of matrices
dev.new(width=10, height=10)
pairs.panels(df[,2:18],method = "pearson",hist.col ="#00AFBB" ,density = TRUE,ellipses = TRUE )
# Scatter plot of matrices
dev.new(width=30, height=30)
pairs.panels(df[,2:18],method = "pearson",hist.col ="#00AFBB" ,density = TRUE,ellipses = TRUE )
# To find out which independent variable to use in our multiple regression we are going to use the step wise regression
null=lm(yr10~1,data=df[,2:18])
full=lm(yr10~.,data=df[,2:18])
step(null,scope=list(upper=full),data=df_train,direction="both")
fit = lm(formula = yr10 ~ morningstar_category + yr5 + life_of_fund +
net_expense_ratio + yr3 + gross_expense_ratio + r2 + ytdDaily +
yr1 + std_dev + last_dividend + beta, data = df[, 2:18])
summary(fit)
# To find out which independent variable to use in our multiple regression we are going to use the step wise regression
null=lm(yr10~1,data=df[,3:18])
full=lm(yr10~.,data=df[,3:18])
step(null,scope=list(upper=full),data=df_train,direction="both")
fit = lm(formula = yr10 ~ yr5 + yr3 + life_of_fund + ytdDaily + yr1 +
r2 + gross_expense_ratio + morningstar_rating_overall + risk +
sharpe_ratio_3_yr + std_dev + net_expense_ratio + minimum_investment,
data = df[, 3:18])
summary(fit)
anova(fit)
# Global Validation of Linear Models Assumptions
gvlma(fit)
