{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies and setup\n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "# from pprint import pprint\n",
    "# import os\n",
    "# import re\n",
    "from splinter import Browser\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 95.0.4638\n",
      "Get LATEST chromedriver version for 95.0.4638 google-chrome\n",
      "Driver [C:\\Users\\mosab\\.wdm\\drivers\\chromedriver\\win32\\95.0.4638.69\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# create a browser instance using splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 funds scraped until page 1\n",
      "200 funds scraped until page 2\n",
      "300 funds scraped until page 3\n",
      "400 funds scraped until page 4\n",
      "500 funds scraped until page 5\n",
      "600 funds scraped until page 6\n",
      "700 funds scraped until page 7\n",
      "800 funds scraped until page 8\n",
      "900 funds scraped until page 9\n",
      "1000 funds scraped until page 10\n",
      "1100 funds scraped until page 11\n",
      "1200 funds scraped until page 12\n",
      "1300 funds scraped until page 13\n",
      "1400 funds scraped until page 14\n",
      "1500 funds scraped until page 15\n",
      "1600 funds scraped until page 16\n",
      "1700 funds scraped until page 17\n",
      "1800 funds scraped until page 18\n",
      "1900 funds scraped until page 19\n",
      "2000 funds scraped until page 20\n",
      "2100 funds scraped until page 21\n",
      "2200 funds scraped until page 22\n",
      "2300 funds scraped until page 23\n",
      "2400 funds scraped until page 24\n",
      "2500 funds scraped until page 25\n",
      "2600 funds scraped until page 26\n",
      "2700 funds scraped until page 27\n",
      "2800 funds scraped until page 28\n",
      "2900 funds scraped until page 29\n",
      "3000 funds scraped until page 30\n",
      "3100 funds scraped until page 31\n",
      "3200 funds scraped until page 32\n",
      "3300 funds scraped until page 33\n",
      "3400 funds scraped until page 34\n",
      "3500 funds scraped until page 35\n",
      "3600 funds scraped until page 36\n",
      "3700 funds scraped until page 37\n",
      "3800 funds scraped until page 38\n",
      "3900 funds scraped until page 39\n",
      "4000 funds scraped until page 40\n",
      "4100 funds scraped until page 41\n",
      "4200 funds scraped until page 42\n",
      "4300 funds scraped until page 43\n",
      "4400 funds scraped until page 44\n",
      "4500 funds scraped until page 45\n",
      "4600 funds scraped until page 46\n",
      "4700 funds scraped until page 47\n",
      "4800 funds scraped until page 48\n",
      "4900 funds scraped until page 49\n",
      "5000 funds scraped until page 50\n",
      "5100 funds scraped until page 51\n",
      "5200 funds scraped until page 52\n",
      "5300 funds scraped until page 53\n",
      "5400 funds scraped until page 54\n",
      "5500 funds scraped until page 55\n",
      "5600 funds scraped until page 56\n",
      "5700 funds scraped until page 57\n",
      "5800 funds scraped until page 58\n",
      "5900 funds scraped until page 59\n",
      "6000 funds scraped until page 60\n",
      "6100 funds scraped until page 61\n",
      "6200 funds scraped until page 62\n",
      "6300 funds scraped until page 63\n",
      "6400 funds scraped until page 64\n",
      "6500 funds scraped until page 65\n",
      "6600 funds scraped until page 66\n",
      "6700 funds scraped until page 67\n",
      "6800 funds scraped until page 68\n",
      "6900 funds scraped until page 69\n",
      "7000 funds scraped until page 70\n",
      "7100 funds scraped until page 71\n",
      "7200 funds scraped until page 72\n",
      "7300 funds scraped until page 73\n",
      "7400 funds scraped until page 74\n",
      "7500 funds scraped until page 75\n",
      "7600 funds scraped until page 76\n",
      "7700 funds scraped until page 77\n",
      "7800 funds scraped until page 78\n",
      "7900 funds scraped until page 79\n",
      "8000 funds scraped until page 80\n",
      "8100 funds scraped until page 81\n",
      "8200 funds scraped until page 82\n",
      "8300 funds scraped until page 83\n",
      "8400 funds scraped until page 84\n",
      "8500 funds scraped until page 85\n",
      "8600 funds scraped until page 86\n",
      "8700 funds scraped until page 87\n",
      "8800 funds scraped until page 88\n",
      "8900 funds scraped until page 89\n",
      "9000 funds scraped until page 90\n",
      "9100 funds scraped until page 91\n",
      "9200 funds scraped until page 92\n",
      "9300 funds scraped until page 93\n",
      "9400 funds scraped until page 94\n",
      "9500 funds scraped until page 95\n",
      "9600 funds scraped until page 96\n",
      "9626 funds scraped until page 97\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "categories = []\n",
    "risks = []\n",
    "stds = []\n",
    "srs = []\n",
    "betas = []\n",
    "r2s = []\n",
    "\n",
    "for i in range(1,98):\n",
    "    fidelity_url = f\"https://fundresearch.fidelity.com/fund-screener/results/table/risk/averageAnnualReturnsYear3/desc/{i}?assetClass=&category=&order=assetClass%2Ccategory\"\n",
    "    browser.visit(fidelity_url)\n",
    "    time.sleep(4)\n",
    "\n",
    "    # create HTML object\n",
    "    html = browser.html\n",
    "\n",
    "    # parse HTML with BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    div = soup.find('div', id ='static-table-container')\n",
    "    table = div.find('table', id = 'static-table')\n",
    "    tbody = table.find('tbody', id = 'static-tbody')\n",
    "    for listing in tbody.find_all('td', class_ = 'name left'):\n",
    "        for name in listing.find_all('a'):\n",
    "            names.append(name.text)\n",
    "\n",
    "    div2 = soup.find('div', id ='scrollable-results-table-wrapper')\n",
    "    table2 = div2.find('table', id = 'scrollable-results-table')\n",
    "    tbody2 = table2.find('tbody', id = 'results-tbody')\n",
    "    for listing in tbody2.find_all('td', class_ = \"morningstarCategory left\"):\n",
    "        category = listing.find('span').text\n",
    "        categories.append(category)\n",
    "    for listing in tbody2.find_all('td', class_ = \"morningstarCategoryRisk center\"):\n",
    "        risk = listing.find('div', class_ = \"risk-icon-gradient\")\n",
    "        risks.append(risk.get(\"class\", \"\")[2][-1])\n",
    "    for listing in tbody2.find_all('td', class_ = \"standardDeviation right\"):\n",
    "        if type(listing.find('span')) == type(None):\n",
    "            stds.append(\"\")\n",
    "        else:\n",
    "            stds.append(listing.find('span').text)\n",
    "    for listing in tbody2.find_all('td', class_ = \"sharpeRatio3Yr right\"):\n",
    "        if type(listing.find('span')) == type(None):\n",
    "            srs.append(\"\")\n",
    "        else:\n",
    "            srs.append(listing.find('span').text)\n",
    "    for listing in tbody2.find_all('td', class_ = \"beta right\"):\n",
    "        if type(listing.find('span')) == type(None):\n",
    "            betas.append(\"\")\n",
    "        else:\n",
    "            betas.append(listing.find('span').text)\n",
    "    for listing in tbody2.find_all('td', class_ = \"r2 right\"):\n",
    "        if type(listing.find('span')) == type(None):\n",
    "            r2s.append(\"\")\n",
    "        else:\n",
    "            r2s.append(listing.find('span').text)\n",
    "    print(f\"{len(names)} funds scraped until page {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>morningstar_category</th>\n",
       "      <th>risk</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>sharpe_ratio_3_yr</th>\n",
       "      <th>beta</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baron Partners Fund Institutional Shares (BPTIX)</td>\n",
       "      <td>Large Growth</td>\n",
       "      <td>6</td>\n",
       "      <td>40.41</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baron Partners Fund Retail Shares (BPTRX)</td>\n",
       "      <td>Large Growth</td>\n",
       "      <td>6</td>\n",
       "      <td>40.39</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Morgan Stanley Institutional Fund, Inc. Incept...</td>\n",
       "      <td>Small Growth</td>\n",
       "      <td>7</td>\n",
       "      <td>40.44</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morgan Stanley Institutional Fund, Inc. Incept...</td>\n",
       "      <td>Small Growth</td>\n",
       "      <td>7</td>\n",
       "      <td>40.48</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morgan Stanley Institutional Fund, Inc. Incept...</td>\n",
       "      <td>Small Growth</td>\n",
       "      <td>7</td>\n",
       "      <td>40.42</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name morningstar_category  \\\n",
       "0   Baron Partners Fund Institutional Shares (BPTIX)         Large Growth   \n",
       "1          Baron Partners Fund Retail Shares (BPTRX)         Large Growth   \n",
       "2  Morgan Stanley Institutional Fund, Inc. Incept...         Small Growth   \n",
       "3  Morgan Stanley Institutional Fund, Inc. Incept...         Small Growth   \n",
       "4  Morgan Stanley Institutional Fund, Inc. Incept...         Small Growth   \n",
       "\n",
       "  risk std_dev sharpe_ratio_3_yr  beta    r2  \n",
       "0    6   40.41              1.60  1.51  0.63  \n",
       "1    6   40.39              1.59  1.51  0.63  \n",
       "2    7   40.44              1.34  1.40  0.71  \n",
       "3    7   40.48              1.32  1.40  0.71  \n",
       "4    7   40.42              1.30  1.40  0.71  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_risk = pd.DataFrame({'name' : names, 'morningstar_category': categories, 'risk': risks, 'std_dev': stds,\\\n",
    "                            'sharpe_ratio_3_yr': srs, 'beta': betas, 'r2': r2s})\n",
    "df_risk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9626 entries, 0 to 9625\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   name                  9626 non-null   object\n",
      " 1   morningstar_category  9626 non-null   object\n",
      " 2   risk                  9626 non-null   object\n",
      " 3   std_dev               9626 non-null   object\n",
      " 4   sharpe_ratio_3_yr     9626 non-null   object\n",
      " 5   beta                  9626 non-null   object\n",
      " 6   r2                    9626 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 526.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_risk.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the browser session    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_risk.to_csv('fidelity_mutual_fund_risk.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
