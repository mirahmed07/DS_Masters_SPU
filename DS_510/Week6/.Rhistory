# Total number of Canadian students surveyed
man_df[-1,-1]
# Total number of Canadian students surveyed
main_df[-1,-1]
# Total number of Canadian students surveyed
main_df[4,4]
# Total number of Canadian students surveyed
main_df[4,7]
# Total number of Canadian students surveyed
main_df[4,6]
# Total number of Canadian students surveyed
main_df[4,3]
# Total number of Canadian students surveyed
main_df[7,4]
max(row_number(main_df))
row_number(main_df)
row.names.data.frame(main_df)
row.names(main_df)
rownames(main_df)
max(rownames(main_df))
# Total number of Canadian students surveyed
main_df[max(rownames(main_df)),4]
max(colnames(main_df))
# Total number of Canadian students surveyed
main_df[max(rownames(main_df)),max(colnames(main_df))]
# The percentage of student enrolled right after high school is
main_df[max(rownames(main_df)),2]/main_df[max(rownames(main_df)),max(colnames(main_df))]
# The percentage of student enrolled right after high school is
main_df[max(rownames(main_df)),2]/main_df[max(rownames(main_df)),max(colnames(main_df))]*100
# The percentage of student enrolled right after high school is
paste(main_df[max(rownames(main_df)),2]/main_df[max(rownames(main_df)),max(colnames(main_df))]*100,"%')
# The percentage of student enrolled right after high school is
paste("l",main_df[max(rownames(main_df)),2]/main_df[max(rownames(main_df)),max(colnames(main_df))]*100,"%')
# The percentage of student enrolled right after high school is
paste0(main_df[max(rownames(main_df)),2]/main_df[max(rownames(main_df)),max(colnames(main_df))]*100,"%')
# The percentage of student enrolled right after high school is
paste0(main_df[max(rownames(main_df)),2]/main_df[max(rownames(main_df)),max(colnames(main_df))]*100,"%")
# The percentage of student enrolled right after high school is
paste0(round(main_df[max(rownames(main_df)),2]/main_df[max(rownames(main_df)),max(colnames(main_df))]*100,2),"%")
# The percentage of student enrolled later is
paste0(round(main_df[max(rownames(main_df)),3]/main_df[max(rownames(main_df)),max(colnames(main_df))]*100,2),"%")
# 6x2 table with observed counts
main_df = merge(x = after_df, y = later_df, by = "Field", all = TRUE)
main_df <- cbind(main_df, Total = rowSums(main_df[2:3]))
main_df <- rbind(main_df, c("Total", colSums(main_df[2:4])))
main_df = transform(main_df, after = as.numeric(after),later = as.numeric(later),Total = as.numeric(Total))
row.names(main_df)  = main_df[,1]
main_df = main_df[,c(2,3,4)]
main_df
# Expected frequencies
xsq = chisq.test(main_df[1:6,1:2], correct = F)
freq_df = data.frame(xsq$expected)
freq_df <- cbind(freq_df, Total = rowSums(freq_df))
freq_df <- rbind(freq_df, c(colSums(freq_df[,1:3])))
rownames(freq_df)[rownames(freq_df)==3]  = c("Total")
freq_df
xsq
# Expected frequencies
xsq = chisq.test(main_df[1:6,1:2], correct = F)
freq_df = data.frame(xsq$expected)
freq_df <- cbind(freq_df, Total = rowSums(freq_df))
freq_df <- rbind(freq_df, c(colSums(freq_df[,1:3])))
rownames(freq_df)[rownames(freq_df)==7]  = c("Total")
freq_df
round(freq_df,2)
#With the given data
dat = data.frame(category = c(1,2,3,4,5), observed = c(139,102,41,78,140))
dat
sum(dat[2])
sum(dat[,2])
sum(dat[1])
sum(dat[2,])
sum(dat[,2])
# Expected count
count(dat)
# Total number of observation
n = sum(dat[,2])
n
dat$prob = dat$observed/n
dat
#With the given data
dat = data.frame(category = c(1,2,3,4,5), observed = c(139,102,41,78,140))
dat
summary(dat)
s = sd(dat$observed)
m = mean(dat$observed)
s
m
pnorm(139,m,s,lower.tail = T)
pnorm(139,m,s,lower.tail = T) + pnorm(139,m,s,lower.tail = F)
pnorm(139,m,s,lower.tail = F)
pnorm(139,m,s,lower.tail = F)
139*139/500
139/500
(139-m)/sd
(139-100)/sd
(139-100)/s
pnorm(-.6,m,s,lower.tail = F)
pnorm(-.6,lower.tail = F)
pnorm(-.6,lower.tail = T)
# For first category, the probability of less than or equal to -0.6
p1 = pnorm(-.6,lower.tail = T)
# For second category, the probability of greater than -0.6 and less than or equal to -0.1
p2 = pnorm(-.1,lower.tail = T) - pnorm(-.6,lower.tail = T)
p2
# For first category, the probability of less than or equal to -0.6
p1 = pnorm(-.6,lower.tail = T)
# For second category, the probability of greater than -0.6 and less than or equal to -0.1
p2 = pnorm(-.1,lower.tail = T) - pnorm(-.6,lower.tail = T)
# For third category, the probability of greater than -0.1 and less than or equal to 0.1
p3 = pnorm(.1,lower.tail = T) - pnorm(-.1,lower.tail = T)
# For fourth category, the probability of greater than 0.1 and less than or equal to 0.6
p4 = pnorm(.6,lower.tail = T) - pnorm(.1,lower.tail = T)
p3
p4
# For first category, the probability of less than or equal to -0.6
p1 = pnorm(-.6,lower.tail = T)
# For second category, the probability of greater than -0.6 and less than or equal to -0.1
p2 = pnorm(-.1,lower.tail = T) - pnorm(-.6,lower.tail = T)
# For third category, the probability of greater than -0.1 and less than or equal to 0.1
p3 = pnorm(.1,lower.tail = T) - pnorm(-.1,lower.tail = T)
# For fourth category, the probability of greater than 0.1 and less than or equal to 0.6
p4 = pnorm(.6,lower.tail = T) - pnorm(.1,lower.tail = T)
# For fifth category, the probability of greater than 0.6
p5 = pnorm(.6,lower.tail = F)
p5
s = sd(dat$observed)
m = mean(dat$observed)
n = count(dat)
n
s = sd(dat$observed)
m = mean(dat$observed)
n = sum(dat)
n
s = sd(dat$observed)
m = mean(dat$observed)
n = sum(dat[,2])
n
dat$expect = c(n*p1, n*p2, n*p3, n*p4, n*p5)
dat
#With the given data
dat = data.frame(category = c(1,2,3,4,5), observed = c(139,102,41,78,140))
dat
summary(dat)
s = sd(dat$observed)
m = mean(dat$observed)
n = sum(dat[,2])
n
# For first category, the probability of less than or equal to -0.6
p1 = pnorm(-.6,lower.tail = T)
# For second category, the probability of greater than -0.6 and less than or equal to -0.1
p2 = pnorm(-.1,lower.tail = T) - pnorm(-.6,lower.tail = T)
# For third category, the probability of greater than -0.1 and less than or equal to 0.1
p3 = pnorm(.1,lower.tail = T) - pnorm(-.1,lower.tail = T)
# For fourth category, the probability of greater than 0.1 and less than or equal to 0.6
p4 = pnorm(.6,lower.tail = T) - pnorm(.1,lower.tail = T)
# For fifth category, the probability of greater than 0.6
p5 = pnorm(.6,lower.tail = F)
p5
dat$expected = c(n*p1, n*p2, n*p3, n*p4, n*p5)
dat
# For first category, the probability of less than or equal to -0.6
p1 = pnorm(-.6,lower.tail = T)
# For second category, the probability of greater than -0.6 and less than or equal to -0.1
p2 = pnorm(-.1,lower.tail = T) - pnorm(-.6,lower.tail = T)
# For third category, the probability of greater than -0.1 and less than or equal to 0.1
p3 = pnorm(.1,lower.tail = T) - pnorm(-.1,lower.tail = T)
# For fourth category, the probability of greater than 0.1 and less than or equal to 0.6
p4 = pnorm(.6,lower.tail = T) - pnorm(.1,lower.tail = T)
# For fifth category, the probability of greater than 0.6
p5 = pnorm(.6,lower.tail = F)
dat$expected = c(n*p1, n*p2, n*p3, n*p4, n*p5)
dat$"(o-E)^2" = (dat$observed-dat$expected)^2
dat
dat$expected = c(n*p1, n*p2, n*p3, n*p4, n*p5)
dat$"(o-E)^2" = (dat$observed-dat$expected)^2
dat$"(o-E)^2/E" = dat$`(o-E)^2`/dat$expected
dat
sum(dat$`(o-E)^2/E`)
# Degree of freedom
count(dat)-1
# Degree of freedom
unname(count(dat)-1)
# Degree of freedom
(count(dat)-1)[1]
# Degree of freedom
(count(dat)-1)[2]
# Degree of freedom
(count(dat)-1)[0]
# Degree of freedom
count(dat)-1
qnorm(sum(dat$`(o-E)^2/E`))
qnorm(3.40687)
qnorm(sqrt(3.40687))
qnorm(1-sqrt(3.40687))
qnorm(sqrt(3.40687)-1)
chisq = sum(dat$`(o-E)^2/E`)
chisq
# Degree of freedom (n-1)
df = count(dat)-1
df
# Degree of freedom (n-1)
d_f = count(dat)-1
d_f
pchisq(chisq, df=d_f, lower.tail=FALSE)
# Degree of freedom (n-1)
d_f = count(dat)-1
d_f.value()
# Degree of freedom (n-1)
d_f = count(dat)-1
value(d_f)
pchisq(chisq, df=d_f[n], lower.tail=FALSE)
pchisq(chisq, df=d_f['n'], lower.tail=FALSE)
pchisq(chisq, df=4, lower.tail=FALSE)
# Degree of freedom (n-1)
d_f = count(dat[1])-1
value(d_f)
# Degree of freedom (n-1)
d_f = count(dat[1])-1
d_f
# Degree of freedom (n-1)
d_f = count(dat[1,])-1
d_f
# Degree of freedom (n-1)
d_f = count(dat[1])-1
d_f
# Degree of freedom (n-1)
d_f = count(dat$category)-1
# Degree of freedom (n-1)
d_f = count(dat$observed)-1
# Degree of freedom (n-1)
d_f = length(dat)-1
d_f
pchisq(chisq, df=d_f, lower.tail=FALSE)
xsq1 = chisq.test(dat[,2], correct = F)
xsq1 = chisq.test(dat[,2], correct = F)
xsq1
xsq1 = chisq.test(dat[,2], correct = T)
xsq1
xsq1 = chisq.test(dat[,2], correct = F)
xsq1
xsq1 = chisq.test(dat$observed, correct = F)
xsq1
xsq1 = chisq.test(dat$observed,, c(p1,p2,p3,p4,p5) correct = F)
xsq1 = chisq.test(dat$observed, c(p1,p2,p3,p4,p5), correct = F)
xsq1
xsq1 = chisq.test(dat$observed, correct = F)
xsq1
x <- c(139,102,41,78,140);
n     <- length(x);
PROB  <- rep(1, times = n)/n;
EXP   <- PROB*sum(x);
CHISQ <- sum((x - EXP)^2/EXP);
df    <- n-1;
P_VAL <- pchisq(CHISQ, df, ncp = 0, lower.tail = FALSE);
CHISQ
P_VAL
x <- c(139,102,41,78,140);
n     <- length(x);
PROB  <- rep(1, times = n)/n;
EXP   <- PROB*sum(x);
CHISQ <- sum((x - EXP)^2/EXP);
df    <- n-1;
P_VAL <- pchisq(CHISQ, df, ncp = 0, lower.tail = FALSE);
EXP
CHISQ
P_VAL
y = x/n
y
y = x/sume(x)
y = x/sum(x)
y
chisq.test(x,y, correct = F)
#load necessary libraries
library(dplyr)
library(readxl)
library(ggplot2)
library(ggpubr)
library(qqplotr)
#library(car)
library(e1071)
library(nortest)
library(BSDA)
# For recruits who were under 20
x1 = 68
n1 = 58952
p1 = round(x1/n1,6)
p1
# For recruits who were at the age of 40 or over
x2 = 3801
n2 = 43786
p2 = round(x2/n2,6)
p2
# Estimate for difference
p1-p2
dat = data.frame(sample = c(1,2), x = c(x1,x2), n = c(n1,n2), P = c(p1,p2))
dat
p_test = prop.test(x = c(x1,x2), n = c(n1,n2), alternative = 'two.sided', conf.level = .99, correct = F)
p_test
# As difference in population proportions is negative
# So Z-value
-unname(sqrt(p_test$statistic))
# 99% confidence interval for the difference in the proportions
p_test$conf.int
# mean / difference in population proportions
m = p1-p2
m
# Standard error of mean / difference
sd = sqrt((p1*(1-p1)/n1) + (p2*(1-p2)/n2))
sd
# pooled estimate
p = (p1*n1+p2*n2)/(n1+n2)
p
# Z-value
z = (p1-p2)/sqrt(p*(1-p)*(1/n1+1/n2))
z
# P-value
pnorm(z,m,sd, lower.tail = T)
# Or
p_test$p.value
n1*p1
n1*(1-p1)
n2*p2
n2*(1-p2)
# For female
n1 = 60
x1 = 48
p1 = x1/n1
p1
se1 = sqrt(p1*(1-p1)/n1)
se1
# For male
n2 = 132
x2 = 52
p2 = x2/n2
p2
se2 = sqrt(p2*(1-p2)/n2)
se2
# Estimate for difference
p1-p2
# pooled estimate
p = (p1*n1+p2*n2)/(n1+n2)
p
options(scipen = n)
p_test = prop.test(x = c(x1,x2), n = c(n1,n2), alternative = 'two.sided', conf.level = .95, correct = F)
p_test
# Z-value
unname(sqrt(p_test$statistic))
#Here
n1 = 57
n2 = 17
n3 = 5
x1 = 6
x2 = 5
x3 = 1
dat = data.frame(Stratum = c("Small", "Medium", "Large"), "Numbers_Allowed" = c(n1-x1,n2-x2,n3-x3), "Numbers_not_allowed" = c(x1,x2,x3), Total = c(n1,n2,n3))
#, Total = c(n1,n2,n3)
dat
dat <- rbind(dat, c("Total", colSums(dat[,2:4])))
dat
#3 × 2 table of counts
dat = transform(dat,  Numbers_Allowed = as.numeric(Numbers_Allowed),Numbers_not_allowed = as.numeric(Numbers_not_allowed),Total = as.numeric(Total))
dat
#the percent of claims that were not allowed in each of the three strata
dat$pct_not_allowed = round(dat$Numbers_not_allowed/dat$Total*100,2)
dat[1:3,c(1,5)]
# Combining medium and large row
dat = subset(dat, select = -c(pct_not_allowed))
dat <- rbind(dat, c("Medium & Large", colSums(dat[2:3,2:4])))
dat = dat[-c(2,3),]
dat = transform(dat, Numbers_Allowed = as.numeric(Numbers_Allowed),Numbers_not_allowed = as.numeric(Numbers_not_allowed),Total = as.numeric(Total))
dat
# reordering the rows
dat = dat[c(1,3,2),]
row.names(dat) <- NULL
dat
row.names(dat)  = dat[,1]
dat = dat[,c(2,3,4)]
dat
# Expected frequencies
xsq = chisq.test(dat[1:2,1:2], correct = F)
freq_df = data.frame(xsq$expected)
freq_df <- cbind(freq_df, Total = rowSums(freq_df))
freq_df <- rbind(freq_df, c(colSums(freq_df[,1:3])))
rownames(freq_df)[rownames(freq_df)==3]  = c("Total")
freq_df
# expected frequency without totals
xsq$expected
# Chi -square test statistics
xsq$statistic
# Degree of freedom
xsq$parameter
# P-value
xsq$p.value
xsq
file_name = "ex09-41canf.xls"
dat = read_xls(file_name)
dat
after_df = filter(dat, Time == 'AfterHS')
after_df$after = after_df$n*after_df$Percent/100
after_df = after_df[c(2,5)]
after_df
later_df = filter(dat, Time == 'Later')
later_df$later = later_df$n*later_df$Percent/100
later_df = later_df[c(2,5)]
later_df
# 6x2 table with observed counts
main_df = merge(x = after_df, y = later_df, by = "Field", all = TRUE)
main_df <- cbind(main_df, Total = rowSums(main_df[2:3]))
main_df <- rbind(main_df, c("Total", colSums(main_df[2:4])))
main_df = transform(main_df, after = as.numeric(after),later = as.numeric(later),Total = as.numeric(Total))
row.names(main_df)  = main_df[,1]
main_df = main_df[,c(2,3,4)]
main_df
# Total number of Canadian students surveyed
main_df[max(rownames(main_df)),max(colnames(main_df))]
# The percentage of student enrolled right after high school is
paste0(round(main_df[max(rownames(main_df)),2]/main_df[max(rownames(main_df)),max(colnames(main_df))]*100,2),"%")
# The percentage of student enrolled later is
paste0(round(main_df[max(rownames(main_df)),3]/main_df[max(rownames(main_df)),max(colnames(main_df))]*100,2),"%")
# Expected frequencies
xsq = chisq.test(main_df[1:6,1:2], correct = F)
freq_df = data.frame(xsq$expected)
freq_df <- cbind(freq_df, Total = rowSums(freq_df))
freq_df <- rbind(freq_df, c(colSums(freq_df[,1:3])))
rownames(freq_df)[rownames(freq_df)==7]  = c("Total")
freq_df
# Chi-square summary
xsq
#With the given data
dat = data.frame(category = c(1,2,3,4,5), observed = c(139,102,41,78,140))
dat
summary(dat)
s = sd(dat$observed)
m = mean(dat$observed)
n = sum(dat[,2])
n
# For first category, the probability of less than or equal to -0.6
p1 = pnorm(-.6,lower.tail = T)
# For second category, the probability of greater than -0.6 and less than or equal to -0.1
p2 = pnorm(-.1,lower.tail = T) - pnorm(-.6,lower.tail = T)
# For third category, the probability of greater than -0.1 and less than or equal to 0.1
p3 = pnorm(.1,lower.tail = T) - pnorm(-.1,lower.tail = T)
# For fourth category, the probability of greater than 0.1 and less than or equal to 0.6
p4 = pnorm(.6,lower.tail = T) - pnorm(.1,lower.tail = T)
# For fifth category, the probability of greater than 0.6
p5 = pnorm(.6,lower.tail = F)
dat$expected = c(n*p1, n*p2, n*p3, n*p4, n*p5)
dat$"(o-E)^2" = (dat$observed-dat$expected)^2
dat$"(o-E)^2/E" = dat$`(o-E)^2`/dat$expected
dat
# Chi-square value
chisq = sum(dat$`(o-E)^2/E`)
chisq
# Degree of freedom (n-1)
d_f = length(dat)-1
d_f
# P-value = P(X^2 >= 3.407)
pchisq(chisq, df=d_f, lower.tail=FALSE)
584*5263.24/13364
setwd("C:/Users/mosab/DS_Masters/DS_510/Week6")
#load necessary libraries
library(dplyr)
library(readxl)
library(ggplot2)
library(ggpubr)
file_name = "simpledata"
df = read.csv(file = file_name)
file_name = "simpledata.csv"
df = read.csv(file = file_name)
df
plot(df$X, df$Y)
#create plot with regression line, regression equation, and R-squared
ggplot(data=df, aes(x=X, y=Y)) +
geom_smooth(method="lm") +
geom_point() +
stat_regline_equation(label.x=10, label.y=50) +
stat_cor(aes(label=..rr.label..), label.x=10, label.y=60)
#create plot with regression line, regression equation, and R-squared
ggplot(data=df, aes(x=X, y=Y)) +
geom_smooth(method="lm") +
geom_point() +
stat_regline_equation(label.x=150, label.y=100) +
stat_cor(aes(label=..rr.label..), label.x=150, label.y=90)
summary(df)
fit<- lm(df$Y ~ df$X)
summary(fit)
b = unname(fit$coefficients[1])
a = unname(fit$coefficients[2])
paste0("Intercept = ",b)
paste0("Slope = ",a)
# Linear Equation
paste0("y =",round(a,2),"x + ",round(b,2))
# Linear Equation
paste0("y = ",round(a,2),"x + ",round(b,2))
# Correlation
cor(df$X,df$Y)
# Correlation
cor(df$Y,df$X)
# Correlation
cor(df$X,df$Y)
a = unname(fit$coefficients[1])
b = unname(fit$coefficients[2])
paste0("Intercept = ",b)
paste0("Slope = ",a)
# Linear Equation
paste0("y = ",round(a,2),"x + ",round(b,2))
str(df)
srt(df)
str(df)
# Correlation
cor(df$X,df$Y)
